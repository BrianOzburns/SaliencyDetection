{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pBg95ePwurGR",
    "outputId": "8d2a667d-6b89-4ea9-9e50-832ec0da493c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.88-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.5.1+cu124)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.20.1+cu124)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2024.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.88-py3-none-any.whl (932 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m932.9/932.9 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.88 ultralytics-thop-2.0.14\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dxFDQtxmuzWp"
   },
   "outputs": [],
   "source": [
    "# load in the video\n",
    "# extract the frames\n",
    "# for the first frame, ask gpt for the rankings\n",
    "# after gpt has the rankings, execute YOLO on the rest of the frames\n",
    "# save the YOLO frames\n",
    "# combine the YOLO frames into a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tnFvp6u6w497"
   },
   "outputs": [],
   "source": [
    "base_drive_path = \"/content/drive/Shared drives/bionic_vision_project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "X4kdIXR-43H2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import sys\n",
    "import base64\n",
    "import json\n",
    "from io import BytesIO\n",
    "\n",
    "OPENAI_API_KEY = \"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\"\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "# from google.colab import userdata\n",
    "# openai.api_key = userdata.get('OPENAI_API_KEY')\n",
    "# os.environ['OPENAI_API_KEY'] = openai.api_key\n",
    "\n",
    "MODEL=\"gpt-4o\"\n",
    "\n",
    "# def encodeImage(image_path):\n",
    "#     \"\"\"Encodes an image file to base64 format for API submission.\"\"\"\n",
    "#     with open(image_path, \"rb\") as image_file:\n",
    "#         return base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "def encodeImage(image, format=\"PNG\"):\n",
    "    \"\"\"Converts a PIL image to a base64-encoded string.\"\"\"\n",
    "    buffered = BytesIO()\n",
    "    image.save(buffered, format=format)  # Save the image to a buffer\n",
    "    return base64.b64encode(buffered.getvalue()).decode()  # Encode to base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "08w-C6Ls44KQ"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def analyzeScene(image_base64, api_key):\n",
    "    \"\"\"Analyzes an image and returns a ranked description.\"\"\"\n",
    "\n",
    "    # Initialize OpenAI client\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "    # OpenAI API request\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an AI that assists visually-impaired individuals by analyzing scenes.\"},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": (\n",
    "                    \"This image is from my point of view. \"\n",
    "                    \"In one sentence, describe to me the setting. \"\n",
    "                    \"In one sentence, describe to me what I am doing. \"\n",
    "                )},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"}}\n",
    "            ]}\n",
    "        ],\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "OqZZdFZ044m0"
   },
   "outputs": [],
   "source": [
    "def rankItems(frame, api_key):\n",
    "    \"\"\"Analyzes an image and returns a ranked description.\"\"\"\n",
    "    # labels\n",
    "    labels = \"person, bicycle, car, motorcycle, airplane, bus, train, truck, boat, traffic light, fire hydrant, stop sign, parking meter, bench, bird, cat, dog, horse, sheep, cow, elephant, bear, zebra, giraffe, backpack, umbrella, handbag, tie, suitcase, frisbee, skis, snowboard, sports ball, kite, baseball bat, baseball glove, skateboard, surfboard, tennis racket, bottle, wine glass, cup, fork, knife, spoon, bowl, banana, apple, sandwich, orange, broccoli, carrot, hot dog, pizza, donut, cake, chair, couch, potted plant, bed, dining table, toilet, tv, laptop, mouse, remote, keyboard, cell phone, microwave, oven, toaster, sink, refrigerator, book, clock, vase, scissors, teddy bear, hair drier, toothbrush\"\n",
    "\n",
    "    # Initialize OpenAI client\n",
    "    client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "    image_pil = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    # Encode image in base64 format\n",
    "    image_base64 = encodeImage(image_pil)\n",
    "\n",
    "    # Get context\n",
    "    context = analyzeScene(image_base64, api_key)\n",
    "\n",
    "    # OpenAI API request\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": (\n",
    "                \"You are an AI that assists visually-impaired individuals by analyzing scenes. \"\n",
    "                \"Always respond in the following JSON format: {\\\"items\\\": [\\\"item1\\\", \\\"item2\\\", ...]}\"\n",
    "            )},\n",
    "            {\"role\": \"assistant\", \"content\": context},\n",
    "            {\"role\": \"assistant\", \"content\": \"all returned items must exist in the following vocabulary: \" + labels},\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"text\", \"text\": (\n",
    "                    \"I am a visually-impaired individual with a retinal implant. \"\n",
    "                    \"I need to see only the most important information in the scene and do not want to be distracted by what is unimportant. \"\n",
    "                    \"Based on what I seem to be doing, rank the 20 most significant physical things in the scene. \"\n",
    "                    \"Consider that large or potentially fast moving objects are likely more significant in scenes rather than smaller objects. \"\n",
    "                    \"As an example, cars are more significant for a visually-impaired indiviual than backpacks.\"\n",
    "                    \"People are important to me.\"\n",
    "                    \"Reason about the context of the scene, and consider what I would want to see in the scene. Ask yourself 'what are the most important objects in the scene?'.\"\n",
    "                    \"All returned objects must exist in the given vocabulary:\" + labels + \". Make sure that this is the case.\"\n",
    "                    \"Return the results strictly as a JSON object with a 'items' field ordered by significance.\"\n",
    "                    \"Each item in the result must be unique.\"\n",
    "                    \"There should be 20 items in the final JSON object\"\n",
    "\n",
    "                )},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"}}\n",
    "            ]}\n",
    "        ],\n",
    "        response_format={ \"type\": \"json_object\" },\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    result_json = json.loads(response.choices[0].message.content)\n",
    "    result = result_json[\"items\"]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_UqeHUqe44yJ"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def top_k_segments(ranking, result, k=4):\n",
    "  all_class_segments = defaultdict(list)\n",
    "  for d in result[0].summary():\n",
    "    class_name = d['name']\n",
    "    if class_name in all_class_segments:\n",
    "      all_class_segments[class_name].append(d['segments'])\n",
    "    else:\n",
    "      all_class_segments[class_name] = [d['segments']]\n",
    "\n",
    "\n",
    "  output_segment = []\n",
    "  top_k = k\n",
    "  for obj in ranking:\n",
    "    if obj in all_class_segments:\n",
    "      output_segment.extend(all_class_segments[obj])\n",
    "      top_k -= 1\n",
    "      if top_k == 0:\n",
    "        break\n",
    "  return output_segment\n",
    "\n",
    "# output_segments = []\n",
    "# for i in range(len(rankings)):\n",
    "#   output_segment = top_k_segments(rankings[i], results[i])\n",
    "#   output_segments.append(output_segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rXoWmKqz4480"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure salient_only_img has the same shape and dtype as img\n",
    "# salient_only_img = np.zeros_like(img, dtype=np.uint8)\n",
    "\n",
    "def getSalientOnlyImg(img, output_segment):\n",
    "  salient_only_img = np.zeros_like(img, dtype=np.uint8)\n",
    "  for segment in output_segment:\n",
    "    points_rollers = [(int(x), int(y)) for x, y in zip(segment['x'], segment['y'])]\n",
    "    data_points = [tuple(point) for point in points_rollers]\n",
    "    # Create a separate single-channel mask\n",
    "    object_mask = np.zeros(img.shape[:2], dtype=np.uint8)  # Grayscale mask\n",
    "    cv2.fillPoly(object_mask, [np.array(data_points)], 255)  # White polygon mask\n",
    "\n",
    "    # Use the mask to extract pixels from the original image and add the extracted pixels to the final image\n",
    "    masked_object = cv2.bitwise_and(img, img, mask=object_mask)\n",
    "    salient_only_img = cv2.add(salient_only_img, masked_object)\n",
    "\n",
    "  return salient_only_img\n",
    "\n",
    "\n",
    "# salient_only_imgs = []\n",
    "# for img, output_segment in zip(processed_images, output_segments):\n",
    "#   salient_only_img = getSalientOnlyImg(img, output_segment)\n",
    "#   salient_only_imgs.append(salient_only_img)\n",
    "\n",
    "# fig, axes = plt.subplots(1, len(processed_images), figsize=(10, 10))\n",
    "# for i, img in enumerate(salient_only_imgs):\n",
    "#   axes[i].imshow(img)\n",
    "#   axes[i].set_title(\"salient segmented objects\")\n",
    "#   axes[i].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "CP_XXFYd45mW"
   },
   "outputs": [],
   "source": [
    "def getStructuralEdges(image, edges):\n",
    "    # Convert the edges to grayscale\n",
    "    edges_gray = cv2.cvtColor(edges, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply thresholding to extract stronger edges (optional)\n",
    "    _, sobel_thresh = cv2.threshold(edges_gray, 50, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Morphological closing to remove small edges\n",
    "    kernel = np.ones((9, 9), np.uint8)\n",
    "    morphed = cv2.morphologyEx(sobel_thresh, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    # Find contours of the edges\n",
    "    contours, _ = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create a blank image to draw the longest edges\n",
    "    long_edges = np.zeros_like(image)\n",
    "\n",
    "    # Filter and draw only the longest contours\n",
    "    min_length = 150   # Adjust this value as needed\n",
    "    for contour in contours:\n",
    "        if cv2.arcLength(contour, closed=False) > min_length:\n",
    "            cv2.drawContours(long_edges, [contour], -1, (255, 255, 255), thickness=1)\n",
    "\n",
    "    return long_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cB0QLbbs45w2"
   },
   "outputs": [],
   "source": [
    "def sobelEdgeDetection(image):\n",
    "    # Load image in grayscale\n",
    "    # image = cv2.imread(image_path, 0)\n",
    "\n",
    "    # Compute Sobel gradients\n",
    "    sobelx = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "    # Combine gradients\n",
    "    edges = cv2.magnitude(sobelx, sobely)\n",
    "\n",
    "    # Normalize and display\n",
    "    edges = np.uint8(255 * edges / np.max(edges))\n",
    "\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "M9-B5e1x457s"
   },
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "def plotEdges(edges, structural=None):\n",
    "    # cv2.imshow('Original Sobel', edges)\n",
    "    cv2_imshow(edges)\n",
    "    if structural is not None:\n",
    "        # cv2.imshow('Longest Edges', structural)\n",
    "        cv2_imshow(structural)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70YQ_oFDwWJv",
    "outputId": "23a05a04-556a-4fcf-f4c8-dd5e058a1329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8m-seg.pt to '/content/drive/Shared drives/bionic_vision_project/yolov8m-seg.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52.4M/52.4M [00:00<00:00, 116MB/s]\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "output_video_path = base_drive_path + \"/video_output/sunset-city-walk-k=2.mp4\"\n",
    "model = YOLO(base_drive_path + \"/yolov8m-seg.pt\")\n",
    "\n",
    "# Open video capture\n",
    "# cap = cv2.VideoCapture(base_drive_path + \"/walking-in-park.mov\")\n",
    "cap = cv2.VideoCapture(base_drive_path + \"/video/sunset-city-walk.mov\")\n",
    "\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# Define codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # or 'XVID' for AVI format\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (frame_width, frame_height))\n",
    "count = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "    if count == 1:\n",
    "      # for the first frame in the video, generate the rankings\n",
    "      # each frame is a numpy array, need to change function definitions for ranking\n",
    "      # rankings = rankItems(image_paths[i] , openai.api_key))\n",
    "      rankings = rankItems(frame, openai.api_key)\n",
    "      print(rankings)\n",
    "\n",
    "\n",
    "    # Run YOLOv8 segmentation on the frame\n",
    "    results = model(frame)\n",
    "\n",
    "    # TODO: get top K segments\n",
    "    output_segment = top_k_segments(rankings, results, k=2)\n",
    "\n",
    "    # TODO: get salient only img\n",
    "    salient_only_img = getSalientOnlyImg(frame, output_segment)\n",
    "\n",
    "    # TODO: get Sobel and Structural Edges\n",
    "\n",
    "    edges = sobelEdgeDetection(salient_only_img)\n",
    "    all_img_edges = sobelEdgeDetection(frame)\n",
    "    structural_edges = getStructuralEdges(frame, all_img_edges)\n",
    "    overlay = cv2.bitwise_or(edges, structural_edges)\n",
    "\n",
    "    # Render the segmentation masks on the frame\n",
    "    #annotated_frame = results[0].plot()  # Renders bounding boxes & masks\n",
    "\n",
    "    # Write the processed frame to output video\n",
    "    out.write(overlay)\n",
    "    print(count)\n",
    "\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
